{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5cea5e-9bfc-469a-ae51-5bbf21c5df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from redis import Redis\n",
    "from redis.commands.search.field import VectorField\n",
    "from redis.commands.search.field import TextField\n",
    "from redis.commands.search.field import TagField\n",
    "from redis.commands.search.query import Query\n",
    "from PIL import Image\n",
    "from img2vec_pytorch import Img2Vec\n",
    "import pickle\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba969e44-d988-43bd-9953-73bdc3c19a1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Amazon Product and Image metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc187a4a-ef97-41fc-92c7-d0c34eb5ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Product data and truncate long text fields\n",
    "all_prods_df = pd.read_csv('data/product_image_data.csv')\n",
    "all_prods_df['primary_key'] = all_prods_df['item_id'] + '-' + all_prods_df['domain_name']\n",
    "all_prods_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c78cdd-49f6-40da-a391-eeb1d2af8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prods_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2261b86-598b-4ab4-be93-e58f34aff3dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Connect to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef37492f-3360-4cd5-8dd2-23ccdd2b9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'vecsim'\n",
    "port = 6379\n",
    "redis_conn = Redis(host = host, port = port)\n",
    "redis_conn.ping()\n",
    "print ('Connected to redis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde0ad07-363e-4414-8684-bbf6c1d13409",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate Embeddings\n",
    "\n",
    "We will use 'Img2Vec' to generate embeddings (vectors) for 1K product images\n",
    "\n",
    "https://github.com/christiansafka/img2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf1ccf-1d3a-4f8b-9457-a9fb648859dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = Img2Vec(cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5298c8d-3b69-4927-93b5-1981ee729f60",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "By Default, Img2Vect uses **'resnet-18'** as the neural network architecture to generate embeddings. In particular, each image is run through this network and the output at the  'avgpool' layer will be returned \n",
    "\n",
    "The output of the 'avgpool' layer in **'resnet-18' has 512 dimensions** so a single 512-float vector will be generated for every image converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78834b6f-c383-453d-bd35-e0613c7274ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_PRODUCTS=100000\n",
    "IMAGE_PATH = './data/images/small/'\n",
    "PRODUCT_IMAGE_VECTOR_FIELD='product_image_vector'\n",
    "IMAGE_VECTOR_DIMENSION=512\n",
    "\n",
    "subset_df = all_prods_df.head(NUMBER_PRODUCTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e5014-228d-45a5-b0e1-bd9a401653cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b14be-3d12-4e2e-9ee8-0e2b368c89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81280b7a-5e22-4fa7-a0fc-77eccfa0de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the df into a dictionary\n",
    "product_metadata = subset_df.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c545978-e9fe-4f27-adcc-2af589761f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check one of the products\n",
    "product_metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22232c6-d272-4bda-9aac-cf36a254b5c2",
   "metadata": {},
   "source": [
    "# Some Utility Functions to Generate Vectors from Images\n",
    "\n",
    "Product images are stored under the 'data/small' folder\n",
    "\n",
    "Every product has metadata indicating the full path to the main product image\n",
    "\n",
    "\n",
    "The 'generate_img2vec_dict' function below simply takes:\n",
    "* A dataframe with product metadata\n",
    "* The folder where images are stored\n",
    "* A batch size to generate image vectors for a batch of products in one call\n",
    "\n",
    "The output will be a dictionary mapping 'full image path' to its corresponding vector generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a040c-160a-49ad-8156-3a5611edaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def generate_img2vec_dict(df,image_path, batch_size=500):\n",
    "    output_dict={}\n",
    "\n",
    "    for batch in chunker(df, batch_size):\n",
    "        image_filenames=batch['path'].values.tolist()\n",
    "        images=[]\n",
    "        converted=[]\n",
    "        \n",
    "        for img_fn in image_filenames:\n",
    "            try:\n",
    "                img = Image.open(image_path + img_fn)\n",
    "                images.append(img)\n",
    "                converted.append(img_fn)\n",
    "            except:\n",
    "                #unable_to_convert -> skip to the next image\n",
    "                continue\n",
    "        \n",
    "        #Generate vectors for all images in this batch\n",
    "        vec_list = img2vec.get_vec(images)\n",
    "        \n",
    "        #update the dictionary to be returned\n",
    "        batch_dict= dict(zip(converted, vec_list))\n",
    "        output_dict.update(batch_dict)\n",
    "        \n",
    "    \n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e9643-155b-4788-8412-e4ba96283ae8",
   "metadata": {},
   "source": [
    "### Time to Load the vectors!\n",
    "\n",
    "Let's load vectors, previously generated, for the the first 100k products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec24277-c079-4ed2-a818-63a125f10379",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with open('100k-image-vectors.npy', 'rb') as handle:\n",
    "    img2vec_dict = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39427b16-dc63-45f9-8a2f-e032d8cb010f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check the Dimensions of one of the vectors generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593534b-9a81-4da3-ae71-7492ef343789",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_key = next(iter(img2vec_dict))\n",
    "first_vector = img2vec_dict[first_key]\n",
    "first_vector.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7f4d2-1c1a-4847-bf6d-b08610b30c01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utility Functions to Load Product metadata and image data\n",
    "Each product will be stored in a redis hash\n",
    "* **Hash Key** = **product:primary_key**\n",
    "* **Hash Fields:** \n",
    "    * Item Id\n",
    "    * Item Name\n",
    "    * Product Image vector = 512-float vector\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b393b-2273-4f26-8779-73896b43c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(client:Redis, product_metadata, vector_dict, vector_field_name):\n",
    "    p = client.pipeline(transaction=False)\n",
    "    for index in product_metadata.keys():    \n",
    "        #hash key\n",
    "        key='product:'+ product_metadata[index]['primary_key']\n",
    "        \n",
    "        #hash values\n",
    "        item_metadata = product_metadata[index]\n",
    "        item_path = item_metadata['path']\n",
    "        \n",
    "        if item_path in vector_dict:\n",
    "            #retrieve vector for product image \n",
    "            product_image_vector = vector_dict[item_path].astype(np.float32).tobytes()\n",
    "            item_metadata[vector_field_name]=product_image_vector\n",
    "            \n",
    "            # HSET\n",
    "            #p.hset(key,mapping=product_data_values)\n",
    "            p.hset(key,mapping=item_metadata)\n",
    "            \n",
    "    p.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5607848c-ce11-44d2-892f-1ffb4778f405",
   "metadata": {},
   "source": [
    "# Utility Functions to Create Indexes on Vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6d4e3-b15d-499e-864d-c420fe140810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flat_index (redis_conn,vector_field_name,number_of_vectors, vector_dimensions=512, distance_metric='L2'):\n",
    "    redis_conn.ft().create_index([\n",
    "        VectorField(vector_field_name, \"FLAT\", {\"TYPE\": \"FLOAT32\", \"DIM\": vector_dimensions, \"DISTANCE_METRIC\": distance_metric, \"INITIAL_CAP\": number_of_vectors, \"BLOCK_SIZE\":number_of_vectors }),\n",
    "        TagField(\"product_type\"),\n",
    "        TextField(\"item_name\"),\n",
    "        TagField(\"country\")        \n",
    "    ])\n",
    "\n",
    "def create_hnsw_index (redis_conn,vector_field_name,number_of_vectors, vector_dimensions=512, distance_metric='L2',M=40,EF=200):\n",
    "    redis_conn.ft().create_index([\n",
    "        VectorField(vector_field_name, \"HNSW\", {\"TYPE\": \"FLOAT32\", \"DIM\": vector_dimensions, \"DISTANCE_METRIC\": distance_metric, \"INITIAL_CAP\": number_of_vectors, \"M\": M, \"EF_CONSTRUCTION\": EF}),\n",
    "        TagField(\"product_type\"),\n",
    "        TextField(\"item_name\"),\n",
    "        TagField(\"country\")     \n",
    "    ])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8085f-b70b-4e8f-831a-21a78d7273a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FLAT - Load and Index Product Data\n",
    "Let's create an index for the image vectors and load information for 100,000 products\n",
    "\n",
    "**This might take 1-2 minutes**\n",
    "\n",
    "A FLAT index is used to perform an exact nearest neighbors search. \n",
    "\n",
    "A query vector will be compared against all other image vectors in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a27ca3-5ce0-4174-aac1-86ffa6224070",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "PRODUCT_IMAGE_VECTOR_FIELD='product_image_vector'\n",
    "IMAGE_VECTOR_DIMENSION=512\n",
    "print ('Loading and Indexing + ' +  str(NUMBER_PRODUCTS) + ' products')\n",
    "\n",
    "#flush all data\n",
    "redis_conn.flushall()\n",
    "\n",
    "#create flat index & load vectors\n",
    "create_flat_index(redis_conn, PRODUCT_IMAGE_VECTOR_FIELD,NUMBER_PRODUCTS,IMAGE_VECTOR_DIMENSION,'COSINE')\n",
    "load_vectors(redis_conn,product_metadata,img2vec_dict,PRODUCT_IMAGE_VECTOR_FIELD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd5a01-5736-4081-b3e4-1551bbb9bd0f",
   "metadata": {},
   "source": [
    "# FLAT index - FIND The Top K MOST VISUALLY Similar Products\n",
    "Let's use the FLAT index to find the exact top K nearest neighbors of a mobile phone cover available in the catalogue \n",
    "\n",
    "The mobile phone product is the first product in the dataset\n",
    "(pos = 0)\n",
    "\n",
    "Feel free to set **pos** to another index in the cell below change the query vector! \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2addde45-9458-440f-8bc8-06092419bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=0\n",
    "print (product_metadata[pos]['item_name'])\n",
    "print (product_metadata[pos]['path'])\n",
    "queryImage = Image.open(IMAGE_PATH + product_metadata[pos]['path'])\n",
    "queryImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370b56a-1cd2-400b-9b97-ecc6750992ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "topK=5\n",
    "query_vector = img2vec.get_vec(queryImage).astype(np.float32).tobytes()\n",
    "\n",
    "#prepare the query\n",
    "q = Query(f'*=>[KNN {topK} @{PRODUCT_IMAGE_VECTOR_FIELD} $vec_param AS vector_score]').sort_by('vector_score').paging(0,topK).return_fields('vector_score','item_name','item_id','path').dialect(2)\n",
    "params_dict = {\"vec_param\": query_vector}\n",
    "\n",
    "#Execute the query\n",
    "results = redis_conn.ft().search(q, query_params = params_dict)\n",
    "\n",
    "#Print similar products found\n",
    "for product in results.docs:\n",
    "    print ('***************Product  found ************')\n",
    "    print (color.BOLD + 'hash key = ' +  color.END + product.id)\n",
    "    print (color.YELLOW + 'Item Name = ' +  color.END  + product.item_name)\n",
    "    print (color.YELLOW + 'Item Id = ' +  color.END  + product.item_id)\n",
    "    print (color.YELLOW + 'Score = ' +  color.END  + product.vector_score)\n",
    "    result_img= Image.open(IMAGE_PATH + product.path)\n",
    "    display(result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a621f9-472d-462f-842c-db39dfb07bc8",
   "metadata": {},
   "source": [
    "## Examine Search Results\n",
    "\n",
    "You can see the redis hash fields projected in the query (e.g item_name, item_path,item_id). \n",
    "\n",
    "The score field returs the distance between the query vector to each of the vectors in the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa427d8-dad0-44e4-bbae-1aea0746f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e748638-50be-4e4f-b953-a87b5fdea311",
   "metadata": {},
   "source": [
    "# HNSW - Load and Index Product Data\n",
    "\n",
    "Let's repeat the exercise of loading and indexing 100,000 products using an HNSW index\n",
    "\n",
    "**This might take 1-2 minutes**\n",
    "\n",
    "This HNSW index is used to calculate Approximate Nearest Neighbors (ANN) of a given vector image. \n",
    "\n",
    "It speeds up query times but requires more memory to store the vector index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551253af-d833-44b3-97dc-4c0e8dd4ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print (f'Loading and Indexing {NUMBER_PRODUCTS} products')\n",
    "#flush all data\n",
    "redis_conn.flushall()\n",
    "#create HNSW index & load vectors\n",
    "create_hnsw_index(redis_conn,PRODUCT_IMAGE_VECTOR_FIELD,NUMBER_PRODUCTS,IMAGE_VECTOR_DIMENSION,'COSINE',M=40,EF=200)\n",
    "load_vectors(redis_conn,product_metadata,img2vec_dict,PRODUCT_IMAGE_VECTOR_FIELD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff708fb3-2926-4201-ab18-d1a6193f569b",
   "metadata": {},
   "source": [
    "# HNSW - Query The Top 5 Similar Products\n",
    "Let's repeat the similarity search but this time using the HNSW index.\n",
    "\n",
    "Let's see the image we're sending in for visual similarity\n",
    "\n",
    "The mobile phone product is the first product in the dataset\n",
    "(pos = 0)\n",
    "\n",
    "Feel free to set **pos** to another index in the cell below change the query vector! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2485f8-3f2b-4234-8b62-0214451f95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=0\n",
    "print (product_metadata[pos]['item_name'])\n",
    "print (product_metadata[pos]['path'])\n",
    "queryImage = Image.open(IMAGE_PATH + product_metadata[pos]['path'])\n",
    "queryImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb687a-2f75-458f-b75c-0a10057a163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "topK=5\n",
    "query_vector = img2vec.get_vec(queryImage).astype(np.float32).tobytes()\n",
    "EF_RUNTIME=200\n",
    "\n",
    "#prepare the query\n",
    "q = Query(f'*=>[KNN {topK} @{PRODUCT_IMAGE_VECTOR_FIELD} $vec_param EF_RUNTIME {EF_RUNTIME} AS vector_score]').sort_by('vector_score').paging(0,topK).return_fields('vector_score','item_name','item_id','path').dialect(2)\n",
    "params_dict = {\"vec_param\": query_vector}\n",
    "\n",
    "#Execute the query\n",
    "results = redis_conn.ft().search(q, query_params = params_dict)\n",
    "docs = redis_conn.ft().search(q,params_dict).docs\n",
    "\n",
    "#Print similar products found\n",
    "for product in results.docs:\n",
    "    print ('***************Product  found ************')\n",
    "    print (color.BOLD + 'hash key = ' +  color.END + product.id)\n",
    "    print (color.YELLOW + 'Item Name = ' +  color.END  + product.item_name)\n",
    "    print (color.YELLOW + 'Item Id = ' +  color.END  + product.item_id)\n",
    "    print (color.YELLOW + 'Score = ' +  color.END  + product.vector_score)\n",
    "    result_img= Image.open(IMAGE_PATH + product.path)\n",
    "    display(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c52fcd-f4ce-4c7e-8b0a-8f0174753ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413eb2f6-d738-47a6-834f-4d64db8b9a0e",
   "metadata": {},
   "source": [
    "# HNSW - Hybrid Query the top 5 most visually similar products ONLY in selected markets\n",
    "\n",
    "Let's repeat our Top 5 search but this time limit to products that meet the following criteria:\n",
    "* **Listed on** Amazon Germany (DE), United States (US) or Italy (IT)\n",
    "\n",
    "\n",
    "This RediSearch query has this form:\n",
    "\n",
    "**(@country:{{DE|US|IT}})=> [KNN 5 vector_field_name $query_vector EF_RUNTIME 10 AS vector_score])**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd623a-6d72-49bb-9837-ac1ffcaeb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "topK=10\n",
    "query_vector = img2vec.get_vec(queryImage).astype(np.float32).tobytes()\n",
    "EF_RUNTIME=200\n",
    "\n",
    "#prepare the query\n",
    "q = Query(f'(@country:{{DE|US|IT}})=>[KNN {topK} @{PRODUCT_IMAGE_VECTOR_FIELD} $vec_param EF_RUNTIME {EF_RUNTIME} AS vector_score]').sort_by('vector_score').paging(0,topK).return_fields('vector_score','item_name','item_id','path','country').dialect(2)\n",
    "params_dict = {\"vec_param\": query_vector}\n",
    "\n",
    "#Execute the query\n",
    "results = redis_conn.ft().search(q, query_params = params_dict)\n",
    "docs = redis_conn.ft().search(q,params_dict).docs\n",
    "\n",
    "#Print similar products found\n",
    "for product in results.docs:\n",
    "    print ('***************Product  found ************')\n",
    "    print (color.BOLD + 'hash key = ' +  color.END + product.id)\n",
    "    print (color.YELLOW + 'Item Name = ' +  color.END  + product.item_name)\n",
    "    print (color.YELLOW + 'Item Id = ' +  color.END  + product.item_id)\n",
    "    print (color.YELLOW + 'Score = ' +  color.END  + product.vector_score)\n",
    "    print (color.YELLOW + 'Country = ' +  color.END  + product.country)\n",
    "    result_img= Image.open(IMAGE_PATH + product.path)\n",
    "\n",
    "    display(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c05474-230f-4f64-8eed-e805879a5fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
